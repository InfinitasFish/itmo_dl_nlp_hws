{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# setup","metadata":{}},{"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm\nimport time\nimport numpy as np\nimport pandas as pd\nimport json\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TrainerCallback, AutoConfig, AutoModel, DataCollatorWithPadding, get_linear_schedule_with_warmup\nfrom peft import PromptTuningConfig, PromptTuningInit, PeftModelForSequenceClassification, LoraConfig\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\n\nMY_SEED = 59\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 16\nMAX_LENGTH = 256\nPROB_LR = 5e-3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:08:24.920676Z","iopub.execute_input":"2025-05-02T16:08:24.920946Z","iopub.status.idle":"2025-05-02T16:08:24.926635Z","shell.execute_reply.started":"2025-05-02T16:08:24.920927Z","shell.execute_reply":"2025-05-02T16:08:24.925866Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"os.environ['TOKENIZERS_PARALLELISM'] = 'true'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:11.147767Z","iopub.execute_input":"2025-05-02T14:37:11.148041Z","iopub.status.idle":"2025-05-02T14:37:11.151831Z","shell.execute_reply.started":"2025-05-02T14:37:11.148020Z","shell.execute_reply":"2025-05-02T14:37:11.151149Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# data","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('dair-ai/emotion')\nlabels_list = dataset['train'].features['label'].names\nlabel2id = {k:v for v, k in enumerate(labels_list)}\nid2label = {v:k for v, k in enumerate(labels_list)}\nprint(dataset)\nprint(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:11.953358Z","iopub.execute_input":"2025-05-02T14:37:11.954078Z","iopub.status.idle":"2025-05-02T14:37:13.400517Z","shell.execute_reply.started":"2025-05-02T14:37:11.954054Z","shell.execute_reply":"2025-05-02T14:37:13.399750Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})\n{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:13.401819Z","iopub.execute_input":"2025-05-02T14:37:13.402097Z","iopub.status.idle":"2025-05-02T14:37:13.538742Z","shell.execute_reply.started":"2025-05-02T14:37:13.402073Z","shell.execute_reply":"2025-05-02T14:37:13.538150Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], max_length=MAX_LENGTH, padding='max_length', truncation=True, return_tensors='pt')\n    \ntokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns='text')\ntokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:13.539723Z","iopub.execute_input":"2025-05-02T14:37:13.540473Z","iopub.status.idle":"2025-05-02T14:37:18.221432Z","shell.execute_reply.started":"2025-05-02T14:37:13.540445Z","shell.execute_reply":"2025-05-02T14:37:18.220710Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42e76f18dcf24a42a4cef19010ae9844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c23382c6f413412e8511271ebd1bb61e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0e02c4ad0043919d45aa5c461db466"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# check","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-uncased', num_labels=6)\nmodel.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:21:02.824244Z","iopub.execute_input":"2025-05-02T14:21:02.824523Z","iopub.status.idle":"2025-05-02T14:21:05.612039Z","shell.execute_reply.started":"2025-05-02T14:21:02.824500Z","shell.execute_reply":"2025-05-02T14:21:05.611084Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370ed5b612c14be293e5f73e2808f883"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def compute_metrics(model, tokenized_dataset, split, labels_list, device, batch_size):\n\n    dataset = tokenized_dataset[split]\n    model.to(device)\n    model.eval()\n    \n    all_predictions = []\n    all_labels = []\n    \n    for i in tqdm(range(0, len(dataset), batch_size)):\n        batch = dataset[i:i+batch_size]\n        \n        inputs = {\n            'input_ids': torch.tensor(batch['input_ids']).to(device),\n            'attention_mask': torch.tensor(batch['attention_mask']).to(device)\n        }\n        labels = torch.tensor(batch['labels']).to(device)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs['logits'] if isinstance(outputs, dict) else outputs\n            predictions = torch.argmax(logits, dim=-1)\n        \n        all_predictions.extend(predictions.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    \n    return classification_report(\n        all_labels,\n        all_predictions,\n        target_names=labels_list,\n        zero_division=0\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:42.346979Z","iopub.execute_input":"2025-05-02T14:37:42.347524Z","iopub.status.idle":"2025-05-02T14:37:42.354938Z","shell.execute_reply.started":"2025-05-02T14:37:42.347492Z","shell.execute_reply":"2025-05-02T14:37:42.354168Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"base_metrics = compute_metrics(model, tokenized_dataset, 'test', labels_list, DEVICE, BATCH_SIZE)\nprint(f'before training metrics:\\n {base_metrics}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:37:43.831968Z","iopub.execute_input":"2025-05-02T14:37:43.832662Z","iopub.status.idle":"2025-05-02T14:38:01.412379Z","shell.execute_reply.started":"2025-05-02T14:37:43.832640Z","shell.execute_reply":"2025-05-02T14:38:01.411780Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb48a231e7114a2aba003b729df57633"}},"metadata":{}},{"name":"stdout","text":"before training metrics:\n               precision    recall  f1-score   support\n\n     sadness       0.30      0.76      0.43       581\n         joy       0.00      0.00      0.00       695\n        love       0.10      0.18      0.13       159\n       anger       0.10      0.05      0.07       275\n        fear       0.15      0.04      0.07       224\n    surprise       0.00      0.00      0.00        66\n\n    accuracy                           0.25      2000\n   macro avg       0.11      0.17      0.12      2000\nweighted avg       0.12      0.25      0.15      2000\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# fine-tune","metadata":{}},{"cell_type":"code","source":"def compute_eval_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {\n        'accuracy': accuracy_score(labels, predictions),\n        'precision': precision_score(labels, predictions, average='macro'),\n        'recall': recall_score(labels, predictions, average='macro'),\n        'f1': f1_score(labels, predictions, average='macro'),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:38:01.413489Z","iopub.execute_input":"2025-05-02T14:38:01.413713Z","iopub.status.idle":"2025-05-02T14:38:01.418009Z","shell.execute_reply.started":"2025-05-02T14:38:01.413696Z","shell.execute_reply":"2025-05-02T14:38:01.417268Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f'trainable parameters: {trainable_params:,}')\n    print(f'total parameters: {total_params:,}')\n    return trainable_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:38:01.418827Z","iopub.execute_input":"2025-05-02T14:38:01.419593Z","iopub.status.idle":"2025-05-02T14:38:01.434929Z","shell.execute_reply.started":"2025-05-02T14:38:01.419575Z","shell.execute_reply":"2025-05-02T14:38:01.434380Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print_trainable_parameters(model);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:21:29.507784Z","iopub.execute_input":"2025-05-02T14:21:29.508354Z","iopub.status.idle":"2025-05-02T14:21:29.513535Z","shell.execute_reply.started":"2025-05-02T14:21:29.508330Z","shell.execute_reply":"2025-05-02T14:21:29.512611Z"}},"outputs":[{"name":"stdout","text":"trainable parameters: 109,486,854\ntotal parameters: 109,486,854\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./models',\n    eval_strategy='epoch',\n    logging_strategy='steps',\n    logging_steps=25,\n    save_strategy='epoch',\n    num_train_epochs=10,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    logging_dir='./logs',\n    metric_for_best_model='f1',\n    load_best_model_at_end=True,\n    save_total_limit=5,\n    seed=MY_SEED,\n    report_to='none',\n    disable_tqdm=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    compute_metrics=compute_eval_metrics,\n    #callbacks=[LossLoggingCallback()],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:56:39.133011Z","iopub.execute_input":"2025-05-02T11:56:39.133781Z","iopub.status.idle":"2025-05-02T11:56:39.170065Z","shell.execute_reply.started":"2025-05-02T11:56:39.133753Z","shell.execute_reply":"2025-05-02T11:56:39.169492Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"torch.cuda.empty_cache()\nstart_time = time.time()\ntorch.cuda.reset_peak_memory_stats()\n\ntrainer.train()\ntraining_time = time.time() - start_time\nmem_usage = torch.cuda.max_memory_allocated() / (1024 * 1024)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T20:55:13.762030Z","iopub.execute_input":"2025-04-30T20:55:13.762541Z","iopub.status.idle":"2025-04-30T22:09:11.586560Z","shell.execute_reply.started":"2025-04-30T20:55:13.762519Z","shell.execute_reply":"2025-04-30T22:09:11.585955Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10000/10000 1:13:56, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.196000</td>\n      <td>0.191988</td>\n      <td>0.931000</td>\n      <td>0.930979</td>\n      <td>0.876240</td>\n      <td>0.899049</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.113000</td>\n      <td>0.167218</td>\n      <td>0.936000</td>\n      <td>0.916049</td>\n      <td>0.909087</td>\n      <td>0.909891</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.151200</td>\n      <td>0.213423</td>\n      <td>0.929500</td>\n      <td>0.912006</td>\n      <td>0.903183</td>\n      <td>0.905983</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.049500</td>\n      <td>0.263794</td>\n      <td>0.928500</td>\n      <td>0.904133</td>\n      <td>0.900045</td>\n      <td>0.900650</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.064300</td>\n      <td>0.268314</td>\n      <td>0.944000</td>\n      <td>0.925033</td>\n      <td>0.917285</td>\n      <td>0.920690</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.022000</td>\n      <td>0.354857</td>\n      <td>0.935000</td>\n      <td>0.905201</td>\n      <td>0.909970</td>\n      <td>0.907333</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.017200</td>\n      <td>0.360507</td>\n      <td>0.940500</td>\n      <td>0.916994</td>\n      <td>0.912228</td>\n      <td>0.914499</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.021700</td>\n      <td>0.404772</td>\n      <td>0.939500</td>\n      <td>0.922165</td>\n      <td>0.907738</td>\n      <td>0.914510</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.007800</td>\n      <td>0.411763</td>\n      <td>0.941000</td>\n      <td>0.917558</td>\n      <td>0.911605</td>\n      <td>0.914533</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.014000</td>\n      <td>0.430650</td>\n      <td>0.938500</td>\n      <td>0.913446</td>\n      <td>0.908424</td>\n      <td>0.910809</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"print(f'gpu max memory util: {mem_usage:.4f} mb')\nprint(f'train time: {(training_time/60):.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T22:14:58.993216Z","iopub.execute_input":"2025-04-30T22:14:58.993699Z"}},"outputs":[{"name":"stdout","text":"gpu max memory util: 4686.5547 mb\ntrain time: 73.9623 mins\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29c8af71a9fb46c2adec8a54edf5479f"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"finetune_metrics = compute_metrics(model, tokenized_dataset, 'test', labels_list, DEVICE, BATCH_SIZE)\nprint(f'after full fine-tune metrics:\\n {finetune_metrics}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# linear-probing","metadata":{}},{"cell_type":"code","source":"class BertBetterHead(nn.Module):\n    def __init__(self, model_name='google-bert/bert-base-uncased', num_labels=6):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(model_name)\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.num_labels = num_labels\n        config = AutoConfig.from_pretrained(model_name)\n        \n        for param in self.bert.parameters():\n            param.requires_grad = False\n            \n        self.head = nn.Sequential(\n            nn.Dropout(0.1),\n            nn.Linear(config.hidden_size, 512),\n            nn.LayerNorm(512),\n            nn.LeakyReLU(),\n            nn.Linear(512, num_labels)\n        )\n\n        self.init_weights()\n\n    def init_weights(self):\n        for module in self.head.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.normal_(module.weight, std=0.02)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n        \n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        embed = outputs.last_hidden_state[:, 0]\n        logits = self.head(embed)\n\n        if labels is not None:\n            loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n            return {'loss': loss, 'logits': logits}\n        \n        return {'logits': logits}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:09:45.892606Z","iopub.execute_input":"2025-05-02T10:09:45.893234Z","iopub.status.idle":"2025-05-02T10:09:45.900453Z","shell.execute_reply.started":"2025-05-02T10:09:45.893209Z","shell.execute_reply":"2025-05-02T10:09:45.899806Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"Сделал два слоя в голове с LeakyReLU, чтобы модель могла находить нелинейные зависимости, перед активацией добавил LayerNorm, чтобы стабилизировать распределения логитов, особенно в самом начале обучения, когда веса рандомные, также добавил Dropout, т.к. модель обучаем глубокую, может быстро переобучиться.","metadata":{}},{"cell_type":"code","source":"model = BertBetterHead()\nmodel.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:09:47.159401Z","iopub.execute_input":"2025-05-02T10:09:47.160009Z","iopub.status.idle":"2025-05-02T10:09:47.569417Z","shell.execute_reply.started":"2025-05-02T10:09:47.159983Z","shell.execute_reply":"2025-05-02T10:09:47.568654Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"print_trainable_parameters(model);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:09:47.570700Z","iopub.execute_input":"2025-05-02T10:09:47.570961Z","iopub.status.idle":"2025-05-02T10:09:47.575438Z","shell.execute_reply.started":"2025-05-02T10:09:47.570935Z","shell.execute_reply":"2025-05-02T10:09:47.574907Z"}},"outputs":[{"name":"stdout","text":"trainable parameters: 397,830\ntotal parameters: 109,880,070\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./models',\n    eval_strategy='epoch',\n    logging_strategy='steps',\n    logging_steps=25,\n    learning_rate=PROB_LR,\n    save_strategy='epoch',\n    num_train_epochs=20,\n    per_device_train_batch_size=BATCH_SIZE*2,\n    per_device_eval_batch_size=BATCH_SIZE*2,\n    logging_dir='./logs',\n    metric_for_best_model='f1',\n    load_best_model_at_end=True,\n    save_total_limit=5,\n    seed=MY_SEED,\n    report_to='none',\n    disable_tqdm=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    compute_metrics=compute_eval_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:09:48.121297Z","iopub.execute_input":"2025-05-02T10:09:48.121678Z","iopub.status.idle":"2025-05-02T10:09:48.155660Z","shell.execute_reply.started":"2025-05-02T10:09:48.121659Z","shell.execute_reply":"2025-05-02T10:09:48.154979Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"torch.cuda.empty_cache()\nstart_time = time.time()\ntorch.cuda.reset_peak_memory_stats()\n\ntrainer.train()\ntraining_time = time.time() - start_time\nmem_usage = torch.cuda.max_memory_allocated() / (1024 * 1024)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:09:49.340726Z","iopub.execute_input":"2025-05-02T10:09:49.341282Z","iopub.status.idle":"2025-05-02T10:56:46.917481Z","shell.execute_reply.started":"2025-05-02T10:09:49.341259Z","shell.execute_reply":"2025-05-02T10:56:46.916697Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10000/10000 46:56, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.294600</td>\n      <td>1.206687</td>\n      <td>0.551500</td>\n      <td>0.362292</td>\n      <td>0.356712</td>\n      <td>0.334277</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.225800</td>\n      <td>1.154270</td>\n      <td>0.568500</td>\n      <td>0.437103</td>\n      <td>0.399231</td>\n      <td>0.394457</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.190300</td>\n      <td>1.135977</td>\n      <td>0.584000</td>\n      <td>0.526561</td>\n      <td>0.440907</td>\n      <td>0.446630</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.132300</td>\n      <td>1.130084</td>\n      <td>0.571000</td>\n      <td>0.586067</td>\n      <td>0.405753</td>\n      <td>0.402018</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.176000</td>\n      <td>1.093585</td>\n      <td>0.588500</td>\n      <td>0.557691</td>\n      <td>0.412124</td>\n      <td>0.417679</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.149100</td>\n      <td>1.097489</td>\n      <td>0.577000</td>\n      <td>0.613276</td>\n      <td>0.383644</td>\n      <td>0.389961</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.193600</td>\n      <td>1.116721</td>\n      <td>0.578500</td>\n      <td>0.508712</td>\n      <td>0.388048</td>\n      <td>0.380577</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.105500</td>\n      <td>1.084485</td>\n      <td>0.585500</td>\n      <td>0.570297</td>\n      <td>0.433671</td>\n      <td>0.434733</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.127400</td>\n      <td>1.089316</td>\n      <td>0.571000</td>\n      <td>0.578818</td>\n      <td>0.404050</td>\n      <td>0.414094</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.085700</td>\n      <td>1.062843</td>\n      <td>0.586500</td>\n      <td>0.564909</td>\n      <td>0.425229</td>\n      <td>0.437346</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.126300</td>\n      <td>1.069532</td>\n      <td>0.593500</td>\n      <td>0.571240</td>\n      <td>0.438645</td>\n      <td>0.458582</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.014100</td>\n      <td>1.080509</td>\n      <td>0.587500</td>\n      <td>0.538018</td>\n      <td>0.466986</td>\n      <td>0.481629</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.035500</td>\n      <td>1.074693</td>\n      <td>0.587500</td>\n      <td>0.569909</td>\n      <td>0.438703</td>\n      <td>0.452446</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.027900</td>\n      <td>1.061965</td>\n      <td>0.593000</td>\n      <td>0.550681</td>\n      <td>0.457492</td>\n      <td>0.470928</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.008000</td>\n      <td>1.057234</td>\n      <td>0.594500</td>\n      <td>0.546713</td>\n      <td>0.456455</td>\n      <td>0.477790</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.979200</td>\n      <td>1.050909</td>\n      <td>0.591500</td>\n      <td>0.546172</td>\n      <td>0.470326</td>\n      <td>0.486067</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.105200</td>\n      <td>1.069870</td>\n      <td>0.589500</td>\n      <td>0.530844</td>\n      <td>0.467447</td>\n      <td>0.482322</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.987200</td>\n      <td>1.051127</td>\n      <td>0.588500</td>\n      <td>0.552792</td>\n      <td>0.457742</td>\n      <td>0.478071</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.985600</td>\n      <td>1.053822</td>\n      <td>0.594000</td>\n      <td>0.554658</td>\n      <td>0.457553</td>\n      <td>0.477341</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.976300</td>\n      <td>1.050026</td>\n      <td>0.597500</td>\n      <td>0.551228</td>\n      <td>0.466656</td>\n      <td>0.486233</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(f'gpu max memory util: {mem_usage:.4f} mb')\nprint(f'train time: {(training_time/60):.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:56:46.918723Z","iopub.execute_input":"2025-05-02T10:56:46.919013Z","iopub.status.idle":"2025-05-02T10:56:46.923057Z","shell.execute_reply.started":"2025-05-02T10:56:46.918994Z","shell.execute_reply":"2025-05-02T10:56:46.922360Z"}},"outputs":[{"name":"stdout","text":"gpu max memory util: 1315.3203 mb\ntrain time: 46.9595 mins\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"probing_metrics = compute_metrics(model, tokenized_dataset, 'test', labels_list, DEVICE, BATCH_SIZE)\nprint(f'linear-probing metrics:\\n {probing_metrics}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:56:46.923841Z","iopub.execute_input":"2025-05-02T10:56:46.924098Z","iopub.status.idle":"2025-05-02T10:57:01.516467Z","shell.execute_reply.started":"2025-05-02T10:56:46.924083Z","shell.execute_reply":"2025-05-02T10:57:01.515906Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"639cce8d4fee41848255817495ca803a"}},"metadata":{}},{"name":"stdout","text":"linear-probing metrics:\n               precision    recall  f1-score   support\n\n     sadness       0.57      0.72      0.64       581\n         joy       0.66      0.79      0.72       695\n        love       0.45      0.21      0.28       159\n       anger       0.58      0.37      0.45       275\n        fear       0.55      0.40      0.46       224\n    surprise       0.53      0.24      0.33        66\n\n    accuracy                           0.60      2000\n   macro avg       0.56      0.45      0.48      2000\nweighted avg       0.59      0.60      0.58      2000\n\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"# prompt-tuning","metadata":{}},{"cell_type":"markdown","source":"Prompt-tuning проще в реализации и менее вычислительно нагружен, для нашей простой задачи классификации в самый раз.","metadata":{}},{"cell_type":"code","source":"bert_base = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-uncased', \n                                                               num_labels=6, return_dict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:03:13.597639Z","iopub.execute_input":"2025-05-02T15:03:13.598215Z","iopub.status.idle":"2025-05-02T15:03:13.775209Z","shell.execute_reply.started":"2025-05-02T15:03:13.598189Z","shell.execute_reply":"2025-05-02T15:03:13.774663Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"peft_config = PromptTuningConfig(\n    task_type='SEQ_CLS',\n    num_virtual_tokens=20,\n    token_dim=768,\n    num_transformer_submodules=1,\n    num_attention_heads=12,\n    num_layers=12,\n    prompt_tuning_init='TEXT',\n    prompt_tuning_init_text='Classify the emotion of this text:',\n    tokenizer_name_or_path='google-bert/bert-base-uncased',\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:03:13.776271Z","iopub.execute_input":"2025-05-02T15:03:13.776605Z","iopub.status.idle":"2025-05-02T15:03:13.780277Z","shell.execute_reply.started":"2025-05-02T15:03:13.776587Z","shell.execute_reply":"2025-05-02T15:03:13.779639Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"model = PeftModelForSequenceClassification(bert_base, peft_config)\nmodel.to(DEVICE)\nprint_trainable_parameters(model);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:03:13.952021Z","iopub.execute_input":"2025-05-02T15:03:13.952571Z","iopub.status.idle":"2025-05-02T15:03:14.381607Z","shell.execute_reply.started":"2025-05-02T15:03:13.952549Z","shell.execute_reply":"2025-05-02T15:03:14.380817Z"}},"outputs":[{"name":"stdout","text":"trainable parameters: 19,974\ntotal parameters: 109,506,828\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer)\n\ntrain_dataloader = DataLoader(tokenized_dataset['train'], shuffle=True, collate_fn=data_collator, batch_size=BATCH_SIZE*2)\nvalid_dataloader = DataLoader(tokenized_dataset['validation'], shuffle=False, collate_fn=data_collator, batch_size=BATCH_SIZE*2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:16:26.342612Z","iopub.execute_input":"2025-05-02T15:16:26.342898Z","iopub.status.idle":"2025-05-02T15:16:26.347202Z","shell.execute_reply.started":"2025-05-02T15:16:26.342877Z","shell.execute_reply":"2025-05-02T15:16:26.346468Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"num_epochs = 8\ncriterion = torch.nn.CrossEntropyLoss()\n\noptimizer = AdamW(params=model.parameters(), lr=PROB_LR)\n\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:16:31.368553Z","iopub.execute_input":"2025-05-02T15:16:31.368826Z","iopub.status.idle":"2025-05-02T15:16:31.374161Z","shell.execute_reply.started":"2025-05-02T15:16:31.368807Z","shell.execute_reply":"2025-05-02T15:16:31.373596Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"Почему-то peft криво работает с trainer в transformers, пришлось писать трейнлуп","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\nstart_time = time.time()\ntorch.cuda.reset_peak_memory_stats()\n\nbest_f1 = 0\nbest_model_state = None\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    all_train_preds = []\n    all_train_labels = []\n    \n    for batch in tqdm(train_dataloader):\n        inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != 'labels'}\n        labels = batch['labels'].to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(**inputs)\n        logits = outputs['logits']\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        \n        total_train_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_train_preds.extend(preds.cpu().numpy())\n        all_train_labels.extend(labels.cpu().numpy())\n    \n    avg_train_loss = total_train_loss / len(train_dataloader)\n    train_acc = accuracy_score(all_train_labels, all_train_preds)\n    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n    \n    model.eval()\n    total_eval_loss = 0\n    all_eval_preds = []\n    all_eval_labels = []\n    \n    for batch in tqdm(valid_dataloader):\n        inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != 'labels'}\n        labels = batch['labels'].to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        logits = outputs['logits']\n        loss = criterion(logits, labels)\n        total_eval_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_eval_preds.extend(preds.cpu().numpy())\n        all_eval_labels.extend(labels.cpu().numpy())\n    \n    avg_eval_loss = total_eval_loss / len(valid_dataloader)\n    eval_acc = accuracy_score(all_eval_labels, all_eval_preds)\n    eval_f1 = f1_score(all_eval_labels, all_eval_preds, average='macro')\n    \n    if eval_f1 > best_f1:\n        best_f1 = eval_f1\n        best_model_state = model.state_dict()\n        torch.save(best_model_state, f'best_model_epoch_{epoch}.pt')\n    \n    print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n    print(f\"Val Loss: {avg_eval_loss:.4f} | Acc: {eval_acc:.4f} | F1: {eval_f1:.4f}\")\n\ntraining_time = time.time() - start_time\nmem_usage = torch.cuda.max_memory_allocated() / (1024 ** 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:16:32.101358Z","iopub.execute_input":"2025-05-02T15:16:32.102273Z","iopub.status.idle":"2025-05-02T16:07:34.375876Z","shell.execute_reply.started":"2025-05-02T15:16:32.102239Z","shell.execute_reply":"2025-05-02T16:07:34.375221Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11656ded83d489187ac3b46f1af22a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f7be6927fb49369ff746248cb2319a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.5817 | Acc: 0.7962 | F1: 0.7406\nVal Loss: 0.4232 | Acc: 0.8585 | F1: 0.8307\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b278e933de24f6f8202f0afe1d4591b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa605b10ccd4d139ee36efe5b9746fd"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.5009 | Acc: 0.8246 | F1: 0.7781\nVal Loss: 0.3773 | Acc: 0.8785 | F1: 0.8496\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de59c6e3c3f421aa9f57ee463b4293e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2957594f2574616a9ebfcb1abb6d43a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.4483 | Acc: 0.8448 | F1: 0.8029\nVal Loss: 0.3282 | Acc: 0.8930 | F1: 0.8714\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8922aeb2764b8b9f0130b0b403f6c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c59bd5b45e94eb3b9c9dc966d75441d"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.4073 | Acc: 0.8559 | F1: 0.8160\nVal Loss: 0.3594 | Acc: 0.8855 | F1: 0.8588\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f307107fe90747bd84a2c97919ec8a6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b977dd5133bf42728aece44187c9a3ed"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3788 | Acc: 0.8668 | F1: 0.8302\nVal Loss: 0.3023 | Acc: 0.8905 | F1: 0.8638\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e92af575c8944ed97db7ba5013e13a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e37cc167e54dd19dabbb1fcdf1eae3"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3498 | Acc: 0.8756 | F1: 0.8405\nVal Loss: 0.3036 | Acc: 0.8930 | F1: 0.8692\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527e1138be284c8792e54daae84b0436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26e0caee40cb44aaa71ca3522b8e7fa5"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3465 | Acc: 0.8764 | F1: 0.8387\nVal Loss: 0.2668 | Acc: 0.8995 | F1: 0.8731\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5ab1b8a64c457d9d86e1eddbf255c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a910ed7b798e43aba76ab0f7d018505f"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3179 | Acc: 0.8861 | F1: 0.8477\nVal Loss: 0.2586 | Acc: 0.9040 | F1: 0.8815\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"print(f'gpu max memory util: {mem_usage:.4f} mb')\nprint(f'train time: {(training_time/60):.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:07:34.376968Z","iopub.execute_input":"2025-05-02T16:07:34.377202Z","iopub.status.idle":"2025-05-02T16:07:34.381338Z","shell.execute_reply.started":"2025-05-02T16:07:34.377185Z","shell.execute_reply":"2025-05-02T16:07:34.380649Z"}},"outputs":[{"name":"stdout","text":"gpu max memory util: 7885.7739 mb\ntrain time: 51.0354 mins\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"# lora","metadata":{}},{"cell_type":"code","source":"bert_base = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-uncased', \n                                                               num_labels=6, return_dict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:16.181095Z","iopub.execute_input":"2025-05-02T16:31:16.181871Z","iopub.status.idle":"2025-05-02T16:31:16.594224Z","shell.execute_reply.started":"2025-05-02T16:31:16.181844Z","shell.execute_reply":"2025-05-02T16:31:16.593674Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"Параметры особо не подбирал, просто поставил R чуть больше, чем дефолтные 8, увеличил alpha, чтобы эффект от лоры было лучше видно (будь он положительным или отрицательным), добавил dropout чтобы не переобучиться, т.к. адаптируем сразу все attention модули.","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type='SEQ_CLS',\n    r=12,\n    lora_alpha=24,\n    bias='lora_only',\n    lora_dropout=0.1,\n    target_modules=['query', 'value', 'key'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:17.408753Z","iopub.execute_input":"2025-05-02T16:31:17.409456Z","iopub.status.idle":"2025-05-02T16:31:17.412936Z","shell.execute_reply.started":"2025-05-02T16:31:17.409433Z","shell.execute_reply":"2025-05-02T16:31:17.412282Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"model = PeftModelForSequenceClassification(bert_base, lora_config)\nmodel.to(DEVICE)\nprint_trainable_parameters(model);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:28.085266Z","iopub.execute_input":"2025-05-02T16:31:28.085938Z","iopub.status.idle":"2025-05-02T16:31:28.304212Z","shell.execute_reply.started":"2025-05-02T16:31:28.085908Z","shell.execute_reply":"2025-05-02T16:31:28.303294Z"}},"outputs":[{"name":"stdout","text":"trainable parameters: 695,814\ntotal parameters: 110,155,020\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer)\n\ntrain_dataloader = DataLoader(tokenized_dataset['train'], shuffle=True, collate_fn=data_collator, batch_size=BATCH_SIZE*2)\nvalid_dataloader = DataLoader(tokenized_dataset['validation'], shuffle=False, collate_fn=data_collator, batch_size=BATCH_SIZE*2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:29.510745Z","iopub.execute_input":"2025-05-02T16:31:29.511491Z","iopub.status.idle":"2025-05-02T16:31:29.515500Z","shell.execute_reply.started":"2025-05-02T16:31:29.511462Z","shell.execute_reply":"2025-05-02T16:31:29.514797Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"num_epochs = 7\ncriterion = torch.nn.CrossEntropyLoss()\n\noptimizer = AdamW(params=model.parameters(), lr=PROB_LR)\n\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:33.841857Z","iopub.execute_input":"2025-05-02T16:31:33.842419Z","iopub.status.idle":"2025-05-02T16:31:33.849466Z","shell.execute_reply.started":"2025-05-02T16:31:33.842378Z","shell.execute_reply":"2025-05-02T16:31:33.848848Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"torch.cuda.empty_cache()\nstart_time = time.time()\ntorch.cuda.reset_peak_memory_stats()\n\nbest_f1 = 0\nbest_model_state = None\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    all_train_preds = []\n    all_train_labels = []\n    \n    for batch in tqdm(train_dataloader):\n        inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != 'labels'}\n        labels = batch['labels'].to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(**inputs)\n        logits = outputs['logits']\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        \n        total_train_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_train_preds.extend(preds.cpu().numpy())\n        all_train_labels.extend(labels.cpu().numpy())\n    \n    avg_train_loss = total_train_loss / len(train_dataloader)\n    train_acc = accuracy_score(all_train_labels, all_train_preds)\n    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n    \n    model.eval()\n    total_eval_loss = 0\n    all_eval_preds = []\n    all_eval_labels = []\n    \n    for batch in tqdm(valid_dataloader):\n        inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != 'labels'}\n        labels = batch['labels'].to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        logits = outputs['logits']\n        loss = criterion(logits, labels)\n        total_eval_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_eval_preds.extend(preds.cpu().numpy())\n        all_eval_labels.extend(labels.cpu().numpy())\n    \n    avg_eval_loss = total_eval_loss / len(valid_dataloader)\n    eval_acc = accuracy_score(all_eval_labels, all_eval_preds)\n    eval_f1 = f1_score(all_eval_labels, all_eval_preds, average='macro')\n    \n    if eval_f1 > best_f1:\n        best_f1 = eval_f1\n        best_model_state = model.state_dict()\n        torch.save(best_model_state, f'best_model_epoch_{epoch}.pt')\n    \n    print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n    print(f\"Val Loss: {avg_eval_loss:.4f} | Acc: {eval_acc:.4f} | F1: {eval_f1:.4f}\")\n\ntraining_time = time.time() - start_time\nmem_usage = torch.cuda.max_memory_allocated() / (1024 ** 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:31:34.851454Z","iopub.execute_input":"2025-05-02T16:31:34.851701Z","iopub.status.idle":"2025-05-02T16:47:42.767189Z","shell.execute_reply.started":"2025-05-02T16:31:34.851686Z","shell.execute_reply":"2025-05-02T16:47:42.766118Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e95dd9a7a945828f2b629be77a91e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e2c5e3aaaa48c1bd7207b87a8af528"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 1.5422 | Acc: 0.3641 | F1: 0.1801\nVal Loss: 1.6208 | Acc: 0.2750 | F1: 0.0719\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a26389dae8d4aa38b4c69f6ae996cdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2675e13c6e70482cb3ba0651e10ee332"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 1.6024 | Acc: 0.3139 | F1: 0.1244\nVal Loss: 1.6021 | Acc: 0.3520 | F1: 0.0868\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9efd95dc22947febee56e8150c57342"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/558244213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mall_train_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;34m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2781\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2782\u001b[0m         \u001b[0mn_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2763\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRowFormat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":83},{"cell_type":"code","source":"mem_usage = torch.cuda.max_memory_allocated() / (1024 ** 2)\nmem_usage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:49:25.245917Z","iopub.execute_input":"2025-05-02T16:49:25.246731Z","iopub.status.idle":"2025-05-02T16:49:25.251503Z","shell.execute_reply.started":"2025-05-02T16:49:25.246705Z","shell.execute_reply":"2025-05-02T16:49:25.250938Z"}},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"8526.68798828125"},"metadata":{}}],"execution_count":87},{"cell_type":"markdown","source":"# summary","metadata":{}},{"cell_type":"markdown","source":"| training method | f1 macro | train params. | gpu usage (mb) | train time (mins) | epochs |\n| --- | --- | --- | --- | --- | --- |\n| without training | 0.06 | - | - | - | - |\n| full fine-tuning | 0.921 | 109,486,854 | 4686.5 | 73.9 | 10 |\n| linear probing | 0.48  | 398,342 | 1315.3 | 46 | 20 |\n| prompt-tuning | 0.881 | 19,974 | 7885 | 51 | 8 |\n| lora | 0.086 | 695,814 | 8526 | 12 | 2 |","metadata":{}},{"cell_type":"markdown","source":"Полный файн-тюнинг - относительно хорошие метрики, долгое обучение и потребление ресурсов.\n\nКастомная голова - метрики сильно ниже, возможно из-за того, что используем нативный берт на задачу, связанную с эмоциями.\n\nPrompt-tuning - медленное обучение (возможно из-за dataloader'ов), мало обучаемых параметров, метрики выше, чем на кастомной голове, F1 сравним с полным тюнингом. Если подобрать параметры лучше и поучить чуть дольше, возможно превзойдет полный тюнинг.\n\nLoRA - слегка по таймингу не успел обучить, упс, минус баллы. Но по первым эпохам динамика довольно странная, как будто она плохо обучится, скорее всего ошибка в том, что я в lora_modules указал key value queue вместо просто attention","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}