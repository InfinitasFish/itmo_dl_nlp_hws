{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## setup","metadata":{}},{"cell_type":"code","source":"!wget http://www.labinform.ru/pub/named_entities/collection5.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:31:58.874822Z","iopub.execute_input":"2025-04-20T14:31:58.875003Z","iopub.status.idle":"2025-04-20T14:32:01.806614Z","shell.execute_reply.started":"2025-04-20T14:31:58.874970Z","shell.execute_reply":"2025-04-20T14:32:01.805872Z"}},"outputs":[{"name":"stdout","text":"--2025-04-20 14:31:58--  http://www.labinform.ru/pub/named_entities/collection5.zip\nResolving www.labinform.ru (www.labinform.ru)... 95.181.230.181\nConnecting to www.labinform.ru (www.labinform.ru)|95.181.230.181|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1899530 (1.8M) [application/zip]\nSaving to: ‘collection5.zip’\n\ncollection5.zip     100%[===================>]   1.81M  1.08MB/s    in 1.7s    \n\n2025-04-20 14:32:01 (1.08 MB/s) - ‘collection5.zip’ saved [1899530/1899530]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!unzip -q /kaggle/working/collection5.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:01.807630Z","iopub.execute_input":"2025-04-20T14:32:01.808443Z","iopub.status.idle":"2025-04-20T14:32:02.093043Z","shell.execute_reply.started":"2025-04-20T14:32:01.808415Z","shell.execute_reply":"2025-04-20T14:32:02.092139Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:02.095259Z","iopub.execute_input":"2025-04-20T14:32:02.095515Z","iopub.status.idle":"2025-04-20T14:32:06.144789Z","shell.execute_reply.started":"2025-04-20T14:32:02.095481Z","shell.execute_reply":"2025-04-20T14:32:06.144109Z"}},"outputs":[{"name":"stdout","text":"Collecting jsonlines\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.3.0)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: jsonlines\nSuccessfully installed jsonlines-4.0.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport random\nimport spacy\nfrom spacy.cli import download\nfrom tqdm.auto import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, get_scheduler, Trainer, TrainingArguments, AutoModelForMaskedLM, pipeline \nfrom datasets import load_dataset\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nswag_seed = 59\ndownload(\"ru_core_news_lg\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:58:21.113839Z","iopub.execute_input":"2025-04-20T14:58:21.114405Z","iopub.status.idle":"2025-04-20T14:59:06.806700Z","shell.execute_reply.started":"2025-04-20T14:58:21.114377Z","shell.execute_reply":"2025-04-20T14:59:06.805907Z"}},"outputs":[{"name":"stdout","text":"Collecting ru-core-news-lg==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 513.4/513.4 MB 3.0 MB/s eta 0:00:00\nRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from ru-core-news-lg==3.7.0) (3.7.5)\nRequirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ru-core-news-lg==3.7.0) (2.0.3)\nRequirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.9.0)\nRequirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (2.4.417150.4580142)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('ru_core_news_lg')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## data","metadata":{}},{"cell_type":"code","source":"ds_path = '/kaggle/working/Collection5'\nprint(len(list(os.listdir(ds_path))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:50.721873Z","iopub.execute_input":"2025-04-20T14:32:50.722710Z","iopub.status.idle":"2025-04-20T14:32:50.728269Z","shell.execute_reply.started":"2025-04-20T14:32:50.722687Z","shell.execute_reply":"2025-04-20T14:32:50.727389Z"}},"outputs":[{"name":"stdout","text":"2000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def parse_ann_file(ann_path, txt_path):\n    entities = []\n    with open(ann_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.startswith('T'):\n                parts = line.strip().split('\\t')\n                id_, tag_info, text = parts\n                tag_parts = tag_info.split()\n                entity_type = tag_parts[0]\n                start = int(tag_parts[1])\n                end = int(tag_parts[2])\n                entities.append((start, end, entity_type))\n                \n    with open(txt_path, 'r', encoding='utf-8') as f:\n        text = f.read().replace('\\n', '\\n ')\n        \n    text_entities = (text, {'entities': entities})\n    \n    return text_entities\n\n\ndef process_dataset(folder_path):\n    data = []\n    files = [f.split('.')[0] for f in os.listdir(folder_path) if f.endswith('.txt')]\n    \n    for file_base in files:\n        txt_path = os.path.join(folder_path, f\"{file_base}.txt\")\n        ann_path = os.path.join(folder_path, f\"{file_base}.ann\")\n        \n        if os.path.exists(ann_path):\n            try:\n                data.append(parse_ann_file(ann_path, txt_path))\n            except Exception as e:\n                print(f\"Error processing {file_base}: {e}\")\n    \n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:50.728985Z","iopub.execute_input":"2025-04-20T14:32:50.729249Z","iopub.status.idle":"2025-04-20T14:32:50.749764Z","shell.execute_reply.started":"2025-04-20T14:32:50.729231Z","shell.execute_reply":"2025-04-20T14:32:50.749088Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def split_dataset(data, test_size=0.2, random_state=swag_seed):\n    train_data, test_data = train_test_split(\n        data, \n        test_size=test_size, \n        random_state=random_state\n    )\n    return train_data, test_data\n\n\ndef prepare_dataset(input_folder):\n    \n    all_data = process_dataset(input_folder)\n    train_data, test_data = split_dataset(all_data)\n\n    print(f\"Total samples: {len(all_data)}\")\n    print(f\"Train samples: {len(train_data)}\")\n    print(f\"Test samples: {len(test_data)}\")\n    \n    label_counts = defaultdict(int)\n    for _, annotations in all_data:\n        for start, end, label in annotations['entities']:\n            label_counts[label] += 1\n\n    print(\"\\nLabel distribution:\")\n    for label, count in label_counts.items():\n        print(f\"{label}: {count}\")\n\n    return train_data, test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:50.751165Z","iopub.execute_input":"2025-04-20T14:32:50.751374Z","iopub.status.idle":"2025-04-20T14:32:50.764478Z","shell.execute_reply.started":"2025-04-20T14:32:50.751359Z","shell.execute_reply":"2025-04-20T14:32:50.763867Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_data, test_data = prepare_dataset(ds_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:50.765195Z","iopub.execute_input":"2025-04-20T14:32:50.765709Z","iopub.status.idle":"2025-04-20T14:32:50.900720Z","shell.execute_reply.started":"2025-04-20T14:32:50.765680Z","shell.execute_reply":"2025-04-20T14:32:50.900188Z"}},"outputs":[{"name":"stdout","text":"Total samples: 1000\nTrain samples: 800\nTest samples: 200\n\nLabel distribution:\nGEOPOLIT: 4104\nORG: 7033\nMEDIA: 1509\nPER: 10623\nLOC: 3140\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"all_labels = set()\nfor _, annotations in train_data:\n    for _, _, label in annotations['entities']:\n        all_labels.add(label)\nfor _, annotations in test_data:\n    for _, _, label in annotations['entities']:\n        all_labels.add(label)\n\nlabel_list = ['O'] + sorted(list(all_labels))\nlabel2id = {label: i for i, label in enumerate(label_list)}\nid2label = {i: label for i, label in enumerate(label_list)}\n\nlabel2id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:50.901335Z","iopub.execute_input":"2025-04-20T14:32:50.901533Z","iopub.status.idle":"2025-04-20T14:32:50.912863Z","shell.execute_reply.started":"2025-04-20T14:32:50.901518Z","shell.execute_reply":"2025-04-20T14:32:50.912331Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'O': 0, 'GEOPOLIT': 1, 'LOC': 2, 'MEDIA': 3, 'ORG': 4, 'PER': 5}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class NERDataset(Dataset):\n    def __init__(self, data, tokenizer, label2id, id2label, max_length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.label2id = label2id\n        self.id2label = id2label\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        text, annotations = item\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            max_length=self.max_length,\n            return_offsets_mapping=True,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        labels = torch.zeros(self.max_length, dtype=torch.long)\n        offset_mapping = encoding['offset_mapping'][0]\n        \n        char_labels = ['O'] * len(text)\n        for start, end, label in annotations['entities']:\n            for i in range(start, end):\n                if i < len(char_labels):\n                    char_labels[i] = label\n        \n        for token_idx, (token_start, token_end) in enumerate(offset_mapping):\n            if token_start == token_end == 0:\n                continue\n            \n            token_char_labels = char_labels[token_start:token_end]\n            \n            unique_labels = set(token_char_labels) - {'O'}\n            if len(unique_labels) == 1:\n                labels[token_idx] = self.label2id[unique_labels.pop()]\n        \n        return {\n            'input_ids': encoding['input_ids'][0],\n            'attention_mask': encoding['attention_mask'][0],\n            'labels': labels,\n        }\n\n    # sinful\n    def print_alignment(self, idx):\n        sample = self[idx]\n        text = self.data[idx][0]\n        tokens = self.tokenizer.convert_ids_to_tokens(sample['input_ids'])\n        labels = [self.id2label[l.item()] for l in sample['labels']]\n        \n        print(\"\\nText:\", text)\n        print(\"\\nToken alignment:\")\n        for token, label in zip(tokens, labels):\n            print(f\"{token:20} {label}\")\n        \n        print(\"\\nOriginal entities:\")\n        for start, end, label in self.data[idx][1]['entities']:\n            print(f\"- {text[start:end]} ({start}-{end}): {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:18:12.481801Z","iopub.execute_input":"2025-04-20T15:18:12.482107Z","iopub.status.idle":"2025-04-20T15:18:12.492086Z","shell.execute_reply.started":"2025-04-20T15:18:12.482058Z","shell.execute_reply":"2025-04-20T15:18:12.491361Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# model_name = 'cointegrated/rubert-tiny2'\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# train_dataset = NERDataset(train_data, tokenizer, label2id, id2label, max_len)\n# train_dataset.print_alignment(9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:04:37.734849Z","iopub.execute_input":"2025-04-20T08:04:37.735025Z","iopub.status.idle":"2025-04-20T08:04:37.747230Z","shell.execute_reply.started":"2025-04-20T08:04:37.735012Z","shell.execute_reply":"2025-04-20T08:04:37.746680Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"model_name = 'cointegrated/rubert-tiny2'\nbatch_size = 64\nlr = 5e-5\nepochs = 20\nmax_len = 256\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:04:37.748039Z","iopub.execute_input":"2025-04-20T08:04:37.748263Z","iopub.status.idle":"2025-04-20T08:04:37.760338Z","shell.execute_reply.started":"2025-04-20T08:04:37.748249Z","shell.execute_reply":"2025-04-20T08:04:37.759819Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def train_model(train_data, test_data, device, label2id, id2label):\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForTokenClassification.from_pretrained(\n        model_name,\n        num_labels=len(label2id),\n        id2label=id2label,\n        label2id=label2id\n    ).to(device)\n    \n    train_dataset = NERDataset(train_data, tokenizer, label2id, id2label, max_len)\n    test_dataset = NERDataset(test_data, tokenizer, label2id, id2label, max_len)\n    \n    train_dataloader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n        shuffle=True\n    )\n    test_dataloader = DataLoader(\n        test_dataset, \n        batch_size=batch_size\n    )\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    num_training_steps = epochs * len(train_dataloader)\n    lr_scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=10,\n        num_training_steps=num_training_steps\n    )\n\n    # eval before and after training\n    evaluate_model(model, test_dataloader, device, label2id, id2label)\n    \n    progress_bar = tqdm(range(num_training_steps))\n    model.train()  \n    for epoch in range(epochs):\n        for batch in train_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            \n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            progress_bar.update(1)\n            progress_bar.set_description(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n    evaluate_model(model, test_dataloader, device, label2id, id2label)\n    return model, tokenizer\n    \n    \ndef evaluate_model(model, test_dataloader, device, label2id, id2label):\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    \n    for batch in test_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        \n        predictions = torch.argmax(outputs.logits, dim=-1)\n        \n        for i in range(predictions.shape[0]):\n            active_tokens = batch['attention_mask'][i] == 1\n            all_predictions.extend(predictions[i][active_tokens].cpu().numpy())\n            all_labels.extend(batch['labels'][i][active_tokens].cpu().numpy())\n    \n    text_labels = [id2label[l] for l in all_labels]\n    text_predictions = [id2label[p] for p in all_predictions]\n    \n    target_names = [label for label in id2label.values() if label != 'O']\n    \n    print(\"\\nClassification Report (excluding 'O' class):\")\n    print(classification_report(\n        text_labels,\n        text_predictions,\n        labels=target_names,\n        zero_division=0\n    ))\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:18:14.942722Z","iopub.execute_input":"2025-04-20T15:18:14.942992Z","iopub.status.idle":"2025-04-20T15:18:14.953300Z","shell.execute_reply.started":"2025-04-20T15:18:14.942973Z","shell.execute_reply":"2025-04-20T15:18:14.952646Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"model, tokenizer = train_model(train_data, test_data, device, label2id, id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:04:37.780296Z","iopub.execute_input":"2025-04-20T08:04:37.780554Z","iopub.status.idle":"2025-04-20T08:06:26.378321Z","shell.execute_reply.started":"2025-04-20T08:04:37.780534Z","shell.execute_reply":"2025-04-20T08:06:26.377629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/401 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c49aae4d92482d895b1a56e8e6e942"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c3a180bad7f426c9757975dbc2a7f55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a90dbb8e73148f281e8cb4212870d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97148d90389b4a2db0fa1b9f1d319b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb01c645ff14bb98d6bd031f970e7e1"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11173555504f4daf95d1336f1bdebdf9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nClassification Report (excluding 'O' class):\n              precision    recall  f1-score   support\n\n    GEOPOLIT       0.02      0.16      0.03       721\n         LOC       0.04      0.40      0.07      1106\n       MEDIA       0.01      0.07      0.01       501\n         ORG       0.02      0.03      0.03      2857\n         PER       0.07      0.07      0.07      5491\n\n   micro avg       0.03      0.10      0.05     10676\n   macro avg       0.03      0.14      0.04     10676\nweighted avg       0.05      0.10      0.05     10676\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/260 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1a2ce739152478a8d9083af9359cd5c"}},"metadata":{}},{"name":"stdout","text":"\nClassification Report (excluding 'O' class):\n              precision    recall  f1-score   support\n\n    GEOPOLIT       0.94      0.67      0.79       721\n         LOC       0.86      0.65      0.74      1106\n       MEDIA       0.99      0.27      0.43       501\n         ORG       0.73      0.82      0.77      2857\n         PER       0.91      0.99      0.95      5491\n\n   micro avg       0.85      0.85      0.85     10676\n   macro avg       0.89      0.68      0.73     10676\nweighted avg       0.86      0.85      0.84     10676\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Пробовал разное кол-во эпох, остановился на 20, т.к. дальше уже начинаются скачки лосса 1.7-1.2 туда-сюда\n\nХуже всего модель научилась предсказывать класс MEDIA, что логично, т.к. это самый редкий класс, и, помимо этого, видов MEDIA, т.е. конкретных журналов, радио, газет и т.д. очень много, и наш датасет их явно не покрывает.\nЭто также заметно по тому, что точность предсказания MEDIA очень хорошая, в то время как реколл очень маленький.","metadata":{}},{"cell_type":"code","source":"outd = '/kaggle/working/clf_v1'  \nmodel.save_pretrained(outd)\ntokenizer.save_pretrained(outd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:06:26.379285Z","iopub.execute_input":"2025-04-20T08:06:26.379505Z","iopub.status.idle":"2025-04-20T08:06:26.736527Z","shell.execute_reply.started":"2025-04-20T08:06:26.379489Z","shell.execute_reply":"2025-04-20T08:06:26.735748Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/clf_v1/tokenizer_config.json',\n '/kaggle/working/clf_v1/special_tokens_map.json',\n '/kaggle/working/clf_v1/vocab.txt',\n '/kaggle/working/clf_v1/added_tokens.json',\n '/kaggle/working/clf_v1/tokenizer.json')"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## mlm","metadata":{}},{"cell_type":"code","source":"class MLMDataset(Dataset):\n        def __init__(self, texts, tokenizer, max_length):\n            self.texts = texts\n            self.tokenizer = tokenizer\n            self.max_length = max_length\n        \n        def __len__(self):\n            return len(self.texts)\n        \n        def __getitem__(self, idx):\n            text = self.texts[idx]\n            encoding = self.tokenizer(\n                text,\n                truncation=True,\n                max_length=self.max_length,\n                padding='max_length',\n                return_tensors='pt'\n            )\n            \n            input_ids = encoding['input_ids'][0].clone()\n            labels = input_ids.clone()\n            \n            mask_prob = 0.15\n            mask_indices = torch.rand(len(input_ids)) < mask_prob\n            \n            special_tokens = [tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id]\n            mask_indices &= ~torch.isin(input_ids, torch.tensor(special_tokens))\n            labels[~mask_indices] = -100\n            \n            mask_token_id = tokenizer.mask_token_id\n            for i, masked in enumerate(mask_indices):\n                if masked:\n                    if torch.rand(1) < 0.8:\n                        input_ids[i] = mask_token_id\n                    elif torch.rand(1) < 0.4:\n                        input_ids[i] = torch.randint(0, len(tokenizer), (1,))\n            \n            return {\n                'input_ids': input_ids,\n                'attention_mask': encoding['attention_mask'][0],\n                'labels': labels\n            }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:19:22.206289Z","iopub.execute_input":"2025-04-20T08:19:22.207092Z","iopub.status.idle":"2025-04-20T08:19:22.213568Z","shell.execute_reply.started":"2025-04-20T08:19:22.207065Z","shell.execute_reply":"2025-04-20T08:19:22.212934Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"В этом датасете задал максимальную длину 128, т.к. если ставить прошлые 256, то кажется, что можно намаскировать \\[PAD] токенов, что не очень желательно ","metadata":{}},{"cell_type":"code","source":"model_name = 'cointegrated/rubert-tiny2'\nbatch_size = 64\nlr = 5e-5\nepochs = 25\nmax_len = 128\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:08:32.580617Z","iopub.execute_input":"2025-04-20T11:08:32.580903Z","iopub.status.idle":"2025-04-20T11:08:32.585204Z","shell.execute_reply.started":"2025-04-20T11:08:32.580881Z","shell.execute_reply":"2025-04-20T11:08:32.584499Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def pretrain_mlm(train_data, model_name, device):\n    \n    texts = [text for text, _ in train_data]\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    mlm_model = AutoModelForMaskedLM.from_pretrained(model_name).to(device)\n    \n    mlm_dataset = MLMDataset(texts, tokenizer, max_len)\n    dataloader = DataLoader(mlm_dataset, batch_size=batch_size, shuffle=True)\n\n    optimizer = torch.optim.AdamW(mlm_model.parameters(), lr=lr)\n    num_training_steps = epochs * len(dataloader)\n    lr_scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=10,\n        num_training_steps=num_training_steps\n    )\n    \n    progress_bar = tqdm(range(num_training_steps))\n    mlm_model.train()\n    \n    for epoch in range(epochs):\n        for batch in dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = mlm_model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            \n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            progress_bar.update(1)\n            progress_bar.set_description(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:42:38.330046Z","iopub.execute_input":"2025-04-20T08:42:38.330622Z","iopub.status.idle":"2025-04-20T08:42:38.336924Z","shell.execute_reply.started":"2025-04-20T08:42:38.330597Z","shell.execute_reply":"2025-04-20T08:42:38.336187Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"mlm_model, mlm_tokenizer = pretrain_mlm(train_data, model_name, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:42:38.692518Z","iopub.execute_input":"2025-04-20T08:42:38.692790Z","iopub.status.idle":"2025-04-20T08:49:04.509039Z","shell.execute_reply.started":"2025-04-20T08:42:38.692769Z","shell.execute_reply":"2025-04-20T08:49:04.508448Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/325 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5821a89020364bc6b967b8c9b36792ca"}},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"outd = '/kaggle/working/mlm_v1'  \nmlm_model.save_pretrained(outd)\nmlm_tokenizer.save_pretrained(outd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:49:51.463971Z","iopub.execute_input":"2025-04-20T08:49:51.464570Z","iopub.status.idle":"2025-04-20T08:49:51.811054Z","shell.execute_reply.started":"2025-04-20T08:49:51.464549Z","shell.execute_reply":"2025-04-20T08:49:51.810409Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/mlm_v1/tokenizer_config.json',\n '/kaggle/working/mlm_v1/special_tokens_map.json',\n '/kaggle/working/mlm_v1/vocab.txt',\n '/kaggle/working/mlm_v1/added_tokens.json',\n '/kaggle/working/mlm_v1/tokenizer.json')"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"def train_model_after_mlm(model, tokenizer, train_data, test_data, device, label2id, id2label):\n    \n    train_dataset = NERDataset(train_data, tokenizer, label2id, id2label, max_len)\n    test_dataset = NERDataset(test_data, tokenizer, label2id, id2label, max_len)\n    \n    train_dataloader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n        shuffle=True\n    )\n    test_dataloader = DataLoader(\n        test_dataset, \n        batch_size=batch_size\n    )\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    num_training_steps = epochs * len(train_dataloader)\n    lr_scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=10,\n        num_training_steps=num_training_steps\n    )\n    \n    progress_bar = tqdm(range(num_training_steps))\n    model.train()  \n    for epoch in range(epochs):\n        for batch in train_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            \n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            progress_bar.update(1)\n            progress_bar.set_description(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n    evaluate_model(model, test_dataloader, device, label2id, id2label)\n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:51:46.464021Z","iopub.execute_input":"2025-04-20T08:51:46.464296Z","iopub.status.idle":"2025-04-20T08:51:46.470952Z","shell.execute_reply.started":"2025-04-20T08:51:46.464274Z","shell.execute_reply":"2025-04-20T08:51:46.470263Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"mlm_ner_model, mlm_ner_tokenizer = train_model_after_mlm(mlm_model, mlm_tokenizer, train_data, test_data, device, label2id, id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:51:48.235974Z","iopub.execute_input":"2025-04-20T08:51:48.236563Z","iopub.status.idle":"2025-04-20T08:53:08.356567Z","shell.execute_reply.started":"2025-04-20T08:51:48.236540Z","shell.execute_reply":"2025-04-20T08:53:08.355789Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/325 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667532c299df41788db0195938ef7ef9"}},"metadata":{}},{"name":"stdout","text":"\nClassification Report (excluding 'O' class):\n              precision    recall  f1-score   support\n\n    GEOPOLIT       0.92      0.87      0.89       470\n         LOC       0.89      0.88      0.88       719\n       MEDIA       0.91      0.82      0.86       379\n         ORG       0.85      0.85      0.85      1686\n         PER       0.96      0.99      0.97      3399\n\n   micro avg       0.92      0.92      0.92      6653\n   macro avg       0.91      0.88      0.89      6653\nweighted avg       0.92      0.92      0.92      6653\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"По сравнению с моделью без mlm претрейна, у которой обучение ner-задачи начиналось с лосса ~3.0 и закончилось на 0.15, у модели с mlm претрейном в начале обучения лосс был 0.1, что даже ниже чем у предыдущей уже обученной модели. Mlm версия после обученмя достигла кросс-энтропии 0.04, что видно и по F1: macro f1 0.73 -> macro f1 0.89, прирост значительный.","metadata":{}},{"cell_type":"markdown","source":"# synth gen","metadata":{}},{"cell_type":"code","source":"lenta_dataset = load_dataset(\"IlyaGusev/ru_news\")\ntexts = []\nfor i, item in tqdm(enumerate(lenta_dataset[\"train\"])):\n    if i > 12000: break\n    texts.append(item[\"text\"])\nprint(len(texts))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:48:46.875952Z","iopub.execute_input":"2025-04-20T14:48:46.876551Z","iopub.status.idle":"2025-04-20T14:48:48.728175Z","shell.execute_reply.started":"2025-04-20T14:48:46.876532Z","shell.execute_reply":"2025-04-20T14:48:48.727436Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeca900547c3490aae9bf124c2328fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0edd148eb9c74b26b605fe453b9c4e93"}},"metadata":{}},{"name":"stdout","text":"12001\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"nlp = spacy.load(\"ru_core_news_lg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:59:06.807933Z","iopub.execute_input":"2025-04-20T14:59:06.808353Z","iopub.status.idle":"2025-04-20T14:59:08.881945Z","shell.execute_reply.started":"2025-04-20T14:59:06.808333Z","shell.execute_reply":"2025-04-20T14:59:08.881372Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"spacy_to_ner = {\n    \"PER\": \"PER\",\n    \"ORG\": \"ORG\",\n    \"LOC\": \"LOC\",\n    \"MISC\": None\n}\n\nMEDIA_KEYWORDS = {\"телеканал\", \"газета\", \"издание\", \"журнал\", \"СМИ\", \"канал\", \"радио\"}\nGEOPOLIT_KEYWORDS = {\"Россия\", \"США\", \"Китай\", \"Франция\", \"Германия\", \"Великобритания\"}\n\ndef is_media(text):\n    return any(keyword in text.lower() for keyword in MEDIA_KEYWORDS)\n\ndef is_geopolit(text):\n    return any(keyword.lower() in text.lower() for keyword in GEOPOLIT_KEYWORDS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:59:08.882685Z","iopub.execute_input":"2025-04-20T14:59:08.882938Z","iopub.status.idle":"2025-04-20T14:59:08.887885Z","shell.execute_reply.started":"2025-04-20T14:59:08.882912Z","shell.execute_reply":"2025-04-20T14:59:08.887302Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def generate_ner_annotations(text):\n    doc = nlp(text)\n    entities = []\n    \n    for ent in doc.ents:\n        custom_label = spacy_to_ner.get(ent.label_)\n        \n        if custom_label:\n            if ent.label_ == \"LOC\":\n                label = \"GEOPOLIT\" if is_geopolit(ent.text) else \"LOC\"\n            else:\n                label = custom_label\n            \n            entities.append((ent.start_char, ent.end_char, label))\n    \n    for match in nlp.tokenizer(text):\n        if is_media(match.text):\n            start = match.idx\n            end = start + len(match.text)\n            entities.append((start, end, \"MEDIA\"))\n    \n    filtered = []\n    for ent in sorted(entities, key=lambda x: x[0]):\n        if not filtered or ent[0] >= filtered[-1][1]:\n            filtered.append(ent)\n    \n    return {\"entities\": filtered}\n\ndef generate_synthetic_dataset(input_texts):\n    results = []\n    \n    for text in tqdm(input_texts):\n        try:\n            annotations = generate_ner_annotations(text)\n            results.append((text, annotations))\n        except Exception as e:\n            print(f\"Ошибка при обработке текста: {str(e)}\")\n            continue\n            \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:59:08.889184Z","iopub.execute_input":"2025-04-20T14:59:08.889381Z","iopub.status.idle":"2025-04-20T14:59:08.903187Z","shell.execute_reply.started":"2025-04-20T14:59:08.889366Z","shell.execute_reply":"2025-04-20T14:59:08.902468Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def check_class_distribution(data):\n    \n    counts = defaultdict(int)\n    \n    for _, annotations in data:\n        for _, _, label in annotations[\"entities\"]:\n            counts[label] += 1\n    \n    print(\"\\nClasses distrib:\")\n    for label, count in sorted(counts.items()):\n        print(f\"{label}: {count}\")\n    \n    return counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:59:08.903767Z","iopub.execute_input":"2025-04-20T14:59:08.903932Z","iopub.status.idle":"2025-04-20T14:59:08.918757Z","shell.execute_reply.started":"2025-04-20T14:59:08.903920Z","shell.execute_reply":"2025-04-20T14:59:08.918046Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"data = generate_synthetic_dataset(texts)\ncheck_class_distribution(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:59:08.919505Z","iopub.execute_input":"2025-04-20T14:59:08.919660Z","iopub.status.idle":"2025-04-20T15:15:51.755952Z","shell.execute_reply.started":"2025-04-20T14:59:08.919647Z","shell.execute_reply":"2025-04-20T15:15:51.755274Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12001 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46cc103b35cf485e9904e9e222f4cf6e"}},"metadata":{}},{"name":"stdout","text":"\nClasses distrib:\nGEOPOLIT: 5478\nLOC: 80314\nMEDIA: 4056\nORG: 73982\nPER: 54888\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"defaultdict(int,\n            {'ORG': 73982,\n             'LOC': 80314,\n             'PER': 54888,\n             'MEDIA': 4056,\n             'GEOPOLIT': 5478})"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"combined_data = train_data + data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:17:42.505803Z","iopub.execute_input":"2025-04-20T15:17:42.506282Z","iopub.status.idle":"2025-04-20T15:17:42.510016Z","shell.execute_reply.started":"2025-04-20T15:17:42.506259Z","shell.execute_reply":"2025-04-20T15:17:42.509469Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"model_name = 'cointegrated/rubert-tiny2'\nbatch_size = 64\nlr = 5e-5\nepochs = 20\nmax_len = 256\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:17:59.282305Z","iopub.execute_input":"2025-04-20T15:17:59.282569Z","iopub.status.idle":"2025-04-20T15:17:59.286596Z","shell.execute_reply.started":"2025-04-20T15:17:59.282551Z","shell.execute_reply":"2025-04-20T15:17:59.286015Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"gen_plus_model, gen_plus_tokenizer = train_model(combined_data, test_data, device, label2id, id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:18:18.541773Z","iopub.execute_input":"2025-04-20T15:18:18.542041Z","iopub.status.idle":"2025-04-20T15:45:22.713439Z","shell.execute_reply.started":"2025-04-20T15:18:18.542021Z","shell.execute_reply":"2025-04-20T15:45:22.712805Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/401 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4e0c775e1d425aabe0059e0799b668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97aacca1321f495aab755a6f13d30ae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b22a4797f744f339606b21e4e2bc54a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4bf617841c7470287312e02a9bbf4ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74bba800896849d6a24254514b0a61f8"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4d47d7f5014489890efd919a93af784"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nClassification Report (excluding 'O' class):\n              precision    recall  f1-score   support\n\n    GEOPOLIT       0.02      0.06      0.03       710\n         LOC       0.01      0.03      0.01       970\n       MEDIA       0.02      0.28      0.03       476\n         ORG       0.05      0.31      0.09      2671\n         PER       0.10      0.08      0.09      5277\n\n   micro avg       0.04      0.14      0.06     10104\n   macro avg       0.04      0.15      0.05     10104\nweighted avg       0.07      0.14      0.07     10104\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4020 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e009baf81354c62bf66f155ca94e829"}},"metadata":{}},{"name":"stdout","text":"\nClassification Report (excluding 'O' class):\n              precision    recall  f1-score   support\n\n    GEOPOLIT       0.95      0.52      0.67       710\n         LOC       0.71      0.92      0.80       970\n       MEDIA       0.70      0.36      0.47       476\n         ORG       0.83      0.94      0.88      2671\n         PER       0.98      0.99      0.98      5277\n\n   micro avg       0.89      0.91      0.90     10104\n   macro avg       0.83      0.74      0.76     10104\nweighted avg       0.90      0.91      0.89     10104\n\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"Модель получилась хуже, чем версия с mlm претрейном, при том, что значение лосса на трейне сильно меньше, чем у модели с mlm. Т.е. можно с большой уверенностью сказать, что модель переобучилась за счет огромного кол-ва новых данных, полученных с помощью spacy. И для лучшего результата, возможно, стоит сгенерировать меньше данных, чтобы их количество было соизмеримо с нашим датасетом, ну или по-крайней мере делать раннюю остановку исходя из метрик на тестовом сплите.\n\nОднако стоит заметить, что переобученная модель лучше всех справилась с классом PERson.\n\nДля наилучшего результата можно было бы ещё попробовать совместить два подхода сразу - mlm + synth gen.\n\nОбычное обучение, mlm, synth gen f1 macro:\n0.73 , 0.89 , 0.76","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}